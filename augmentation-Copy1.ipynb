{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d9a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c29f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072e099b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3d7b23cbb3c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mparsed_image_dataset_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "recordfile = r\"E:\\Kuliah\\Bangkit\\Capstone\\Dataset\\DatasetTFRecord\\UFPR-ALPR.tfrecords\"\n",
    "raw_dataset = tf.data.TFRecordDataset(recordfile)\n",
    "raw_dataset\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/51409906/converting-tfrecords-back-into-jpeg-images\n",
    "image_feature_description = {\n",
    "    'image/height': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    'image/width': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    'image/filename': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'image/format': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'image/object/bbox/ymin': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'image/object/class/text': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'image/object/class/label': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def _parse_image_sequences_function(example_proto):\n",
    "    return tf.io.parse_sequence_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = raw_dataset.map(_parse_image_function)\n",
    "parsed_image_dataset\n",
    "\n",
    "parsed_image_dataset_sequence = raw_dataset.map(_parse_image_sequences_function)\n",
    "parsed_image_dataset_sequence\n",
    "\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(record)\n",
    "feat = example.features.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c63adea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2a8e233a4a40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image/filename\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbytes_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mfeat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image/encoded\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbytes_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# boxes = feat[\"image/object/bbox/xmin\"].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg_buffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = feat[\"image/filename\"].bytes_list.value[0].decode(\"utf-8\")\n",
    "img =  feat[\"image/encoded\"].bytes_list.value[0]\n",
    "# boxes = feat[\"image/object/bbox/xmin\"].\n",
    "img_buffer = io.BytesIO(img)\n",
    "Image.open(img_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3fbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
